{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10.10 Prac 2. Document Classification연습.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNpyyElIx4ljf+Iujr9uiob",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hugekyung/NLP/blob/master/Document_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoN2b2_bwTjq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "1fe7ffaf-66a1-4275-a5c6-e08853b0e2bb"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)\n",
        "print(twenty_train.target_names) #뉴스 카테고리 출력\n",
        "print(twenty_train.data[0]) #뉴스 데이터 출력"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "- IL\n",
            "   ---- brought to you by your neighborhood Lerxst ----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhrwFH30wisV",
        "colab_type": "text"
      },
      "source": [
        "Pipeline을 활용한 문서분류"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMbGEZD1wdLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "text_clf = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
        "                     ('clf', MultinomialNB(alpha=0.001)), ])\n",
        "\n",
        "text_clf = text_clf.fit(twenty_train.data, twenty_train.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2tBmohQxVa7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a6f9f9f-e208-4991-fbce-54ee5e1643ee"
      },
      "source": [
        "import numpy as np\n",
        "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
        "predicted = text_clf.predict(twenty_test.data)\n",
        "np.mean(predicted == twenty_test.target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8255443441317047"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_FD-T-txwV1",
        "colab_type": "text"
      },
      "source": [
        "Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGyeoTRlxyjR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        },
        "outputId": "a9b2140e-3c1e-4ac7-822d-18b254674a79"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters_clf = {'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
        "                  'tfidf__use_idf': (True, False),\n",
        "                  'tfidf__sublinear_tf': (True, False),\n",
        "                  }\n",
        "gs_clf = GridSearchCV(text_clf, parameters_clf, n_jobs=-1, verbose=2)\n",
        "gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)\n",
        "print(\"Best score: {0}\".format(gs_clf.best_score_))  \n",
        "print(\"Best parameters set:\")\n",
        "best_parameters = gs_clf.best_estimator_.get_params()\n",
        "for param_name in sorted(list(best_parameters.keys())):  \n",
        "    print(\"\\t{0}: {1}\".format(param_name, best_parameters[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  6.0min\n",
            "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 10.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.9181550120279607\n",
            "Best parameters set:\n",
            "\tclf: MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True)\n",
            "\tclf__alpha: 0.001\n",
            "\tclf__class_prior: None\n",
            "\tclf__fit_prior: True\n",
            "\tmemory: None\n",
            "\tsteps: [('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
            "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
            "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
            "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                tokenizer=None, vocabulary=None)), ('tfidf', TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=True, use_idf=True)), ('clf', MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True))]\n",
            "\ttfidf: TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=True, use_idf=True)\n",
            "\ttfidf__norm: l2\n",
            "\ttfidf__smooth_idf: True\n",
            "\ttfidf__sublinear_tf: True\n",
            "\ttfidf__use_idf: True\n",
            "\tvect: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
            "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
            "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
            "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                tokenizer=None, vocabulary=None)\n",
            "\tvect__analyzer: word\n",
            "\tvect__binary: False\n",
            "\tvect__decode_error: strict\n",
            "\tvect__dtype: <class 'numpy.int64'>\n",
            "\tvect__encoding: utf-8\n",
            "\tvect__input: content\n",
            "\tvect__lowercase: True\n",
            "\tvect__max_df: 1.0\n",
            "\tvect__max_features: None\n",
            "\tvect__min_df: 1\n",
            "\tvect__ngram_range: (1, 2)\n",
            "\tvect__preprocessor: None\n",
            "\tvect__stop_words: None\n",
            "\tvect__strip_accents: None\n",
            "\tvect__token_pattern: (?u)\\b\\w\\w+\\b\n",
            "\tvect__tokenizer: None\n",
            "\tvect__vocabulary: None\n",
            "\tverbose: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VR4Sy5v5xK7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6331082-8dde-464c-fe41-038b8fe520a0"
      },
      "source": [
        "import numpy as np\n",
        "predicted = gs_clf.best_estimator_.predict(twenty_test.data)\n",
        "np.mean(predicted == twenty_test.target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.83935209771641"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}